{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import s3fs\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session, role, bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()             # IAM role to use by SageMaker\n",
    "\n",
    "s3_bucket = sagemaker_session.default_bucket()\n",
    "s3_prefix = 'MLEND-Capstone-Project'    \n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_data_path = \"s3://{}/{}/data_indicator\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output_indicator\".format(s3_bucket, s3_prefix)\n",
    "\n",
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1:  3268098\n",
      " 0:  3220281\n",
      " 1:  4107528\n"
     ]
    }
   ],
   "source": [
    "stock_indicator_data = pd.read_csv('stock_indicator_data.csv',parse_dates=True, index_col=[0,1])\n",
    "get_target_distribution(stock_indicator_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = get_sp500_tickers()\n",
    "\n",
    "freq = 'D'\n",
    "\n",
    "# we predict for 1 day\n",
    "prediction_length = 1\n",
    "\n",
    "# we use 50 days as context length, this is the number of state updates accomplished before making predictions\n",
    "context_length = 50\n",
    "\n",
    "end_training = pd.Timestamp('2018-12-31', freq=freq)\n",
    "\n",
    "timeseries = []\n",
    "    \n",
    "for ID,ticker in list(enumerate(tickers)):\n",
    "    ticker = stock_indicator_data.loc[(slice(None), ticker), :]\n",
    "    if ticker.index[0][0]<end_training:\n",
    "        timeseries.append(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491\n"
     ]
    }
   ],
   "source": [
    "dynamic_feat = ['Adj Close','Volume','PC1','PC2','PC3','PC4','PC5','PC6']\n",
    "training_data = [\n",
    "    {\n",
    "            \"start\": str(ts.index[0][0]),\n",
    "            \"target\": ts['target'][ts.index[0][0]:end_training].tolist(), # We use -1, because pandas indexing includes the upper bound \n",
    "            \"dynamic_feat\": ts[dynamic_feat][ts.index[0][0]:end_training].values.T.tolist()\n",
    "    }\n",
    "    for ts in timeseries\n",
    "]\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:10: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4910\n"
     ]
    }
   ],
   "source": [
    "num_test_windows = 10\n",
    "\n",
    "test_data = [\n",
    "    {\n",
    "        \"start\": str(ts.index[0][0]),\n",
    "        \"target\": ts['target'][ts.index[0][0]:end_training + (2*k * prediction_length)].tolist(),\n",
    "        \"dynamic_feat\": ts[['Adj Close','Volume','PC1','PC2','PC3','PC4','PC5','PC6']][ts.index[0][0]:end_training + (2*k * prediction_length)].values.T.tolist()\n",
    "    }\n",
    "    for k in range(1, num_test_windows + 1) \n",
    "    for ts in timeseries\n",
    "]\n",
    "print(len(test_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 3.15 s, total: 1min 10s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_json_dataset(\"train_indicator.json\", training_data)\n",
    "write_json_dataset(\"test_indicator.json\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File s3://sagemaker-us-east-2-017500148529/s3://sagemaker-us-east-2-017500148529/MLEND-Capstone-Project/data_indicator/train/train.json already exists.\n",
      "Set override to upload anyway.\n",
      "\n",
      "File s3://sagemaker-us-east-2-017500148529/s3://sagemaker-us-east-2-017500148529/MLEND-Capstone-Project/data_indicator/test/test.json already exists.\n",
      "Set override to upload anyway.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "copy_to_s3(\"train_indicator.json\", s3_data_path + \"/train/train.json\", s3_bucket)\n",
    "copy_to_s3(\"test_indicator.json\", s3_data_path + \"/test/test.json\", s3_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2010-03-16 00:00:00\", \"target\": [1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, -1, 1, 1, 1, 1, 1...\n"
     ]
    }
   ],
   "source": [
    "s3filesystem = s3fs.S3FileSystem()\n",
    "with s3filesystem.open(s3_data_path + \"/train/train.json\", 'rb') as fp:\n",
    "    print(fp.readline().decode(\"utf-8\")[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_indicator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='MLEND-Capstone-Project',\n",
    "    output_path=s3_output_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"100\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"num_dynamic_feat\": 'auto',\n",
    "}\n",
    "estimator_indicator.set_hyperparameters(**hyperparameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 8.34 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\n",
    "    \"train\": s3_data_path + \"/train/train.json\",\n",
    "    \"test\": s3_data_path + \"/test/test.json\"\n",
    "}\n",
    "\n",
    "#estimator_indicator.fit(inputs=data_channels, wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "#predictor_indicator = estimator_indicator.deploy(\n",
    "#    initial_instance_count=1,\n",
    "#    instance_type='ml.m4.xlarge',\n",
    "#    content_type=\"application/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_indicator = sagemaker.predictor.RealTimePredictor(endpoint='MLEND-Capstone-Project-2020-06-03-23-30-23-410')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/MLEND-Capstone-Project/helper.py:89: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  date_start = date_pred-50\n",
      "/home/ec2-user/SageMaker/MLEND-Capstone-Project/helper.py:94: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  \"target\": pred_df['target'][date_start:date_pred-1].tolist(),\n",
      "/home/ec2-user/SageMaker/MLEND-Capstone-Project/helper.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  result_df['prediction'] = pred\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.043087</td>\n",
       "      <td>-1.389812</td>\n",
       "      <td>7.484644</td>\n",
       "      <td>3.785415</td>\n",
       "      <td>-4.228811</td>\n",
       "      <td>0.443095</td>\n",
       "      <td>1.235278</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Close    Volume       PC1       PC2       PC3  \\\n",
       "Date       Ticker                                                      \n",
       "2019-01-02 AAPL      0.03987  0.043087 -1.389812  7.484644  3.785415   \n",
       "\n",
       "                        PC4       PC5       PC6  target  prediction  \n",
       "Date       Ticker                                                    \n",
       "2019-01-02 AAPL   -4.228811  0.443095  1.235278      -1          -1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_prediction('AAPL', '2019-01-02',stock_indicator_data,predictor_indicator, ['Adj Close','Volume','PC1','PC2','PC3','PC4','PC5','PC6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/MLEND-Capstone-Project/helper.py:89: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  date_start = date_pred-50\n",
      "/home/ec2-user/SageMaker/MLEND-Capstone-Project/helper.py:94: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  \"target\": pred_df['target'][date_start:date_pred-1].tolist(),\n",
      "/home/ec2-user/SageMaker/MLEND-Capstone-Project/helper.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  result_df['prediction'] = pred\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7301587301587301,             target  prediction\n",
       " 2019-01-02      -1          -1\n",
       " 2019-01-03       1          -1\n",
       " 2019-01-04       1           1\n",
       " 2019-01-07       1           1\n",
       " 2019-01-08       1           1\n",
       " 2019-01-09       1           1\n",
       " 2019-01-10       1           1\n",
       " 2019-01-11       0           1\n",
       " 2019-01-14       1           0\n",
       " 2019-01-15       1           1\n",
       " 2019-01-16       1           1\n",
       " 2019-01-17       1           1\n",
       " 2019-01-18       1           1\n",
       " 2019-01-22       1           1\n",
       " 2019-01-23       1           1\n",
       " 2019-01-24       1           1\n",
       " 2019-01-25       1           1\n",
       " 2019-01-28       1           1\n",
       " 2019-01-29       1           1\n",
       " 2019-01-30       0           1\n",
       " 2019-01-31       0           0\n",
       " 2019-02-01       0           0\n",
       " 2019-02-04       0           0\n",
       " 2019-02-05       0           0\n",
       " 2019-02-06       1           0\n",
       " 2019-02-07       1           1\n",
       " 2019-02-08       1           1\n",
       " 2019-02-11       1           1\n",
       " 2019-02-12       0           1\n",
       " 2019-02-13       1           0\n",
       " ...            ...         ...\n",
       " 2019-11-18       1           1\n",
       " 2019-11-19       0           1\n",
       " 2019-11-20       1           0\n",
       " 2019-11-21       1           1\n",
       " 2019-11-22       1           1\n",
       " 2019-11-25       0           1\n",
       " 2019-11-26       0           0\n",
       " 2019-11-27       0           0\n",
       " 2019-11-29       1           0\n",
       " 2019-12-02       1           1\n",
       " 2019-12-03       1           1\n",
       " 2019-12-04       1           1\n",
       " 2019-12-05       1           1\n",
       " 2019-12-06       1           1\n",
       " 2019-12-09       1           1\n",
       " 2019-12-10       0           1\n",
       " 2019-12-11       0           0\n",
       " 2019-12-12       0           0\n",
       " 2019-12-13       0           0\n",
       " 2019-12-16       0           0\n",
       " 2019-12-17       0           0\n",
       " 2019-12-18       1           0\n",
       " 2019-12-19       0           1\n",
       " 2019-12-20       0           0\n",
       " 2019-12-23       0           0\n",
       " 2019-12-24       0           0\n",
       " 2019-12-26       0           0\n",
       " 2019-12-27       0           0\n",
       " 2019-12-30       0           0\n",
       " 2019-12-31       0           0\n",
       " \n",
       " [252 rows x 2 columns])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_index = pd.read_csv('test_date_index.csv')\n",
    "date_index = date_index.values.reshape(252).tolist()\n",
    "get_prediction_accuracy('A', date_index, stock_indicator_data,predictor_indicator,['Adj Close','Volume','PC1','PC2','PC3','PC4','PC5','PC6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
