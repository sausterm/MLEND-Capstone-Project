{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas-datareader\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/52/accb990baebe0063977f26e02df36aa7eb4015ed4e86f828cd76273cd6f1/pandas_datareader-0.8.1-py2.py3-none-any.whl (107kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 2.9MB/s ta 0:00:01   28% |█████████▏                      | 30kB 2.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.21 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas-datareader) (0.24.2)\n",
      "Requirement already satisfied: lxml in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas-datareader) (4.2.1)\n",
      "Requirement already satisfied: requests>=2.3.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas-datareader) (2.20.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas>=0.21->pandas-datareader) (1.14.6)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas>=0.21->pandas-datareader) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas>=0.21->pandas-datareader) (2018.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.3.0->pandas-datareader) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.3.0->pandas-datareader) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.3.0->pandas-datareader) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests>=2.3.0->pandas-datareader) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.21->pandas-datareader) (1.11.0)\n",
      "Installing collected packages: pandas-datareader\n",
      "Successfully installed pandas-datareader-0.8.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas-datareader\n",
    "import boto3\n",
    "import s3fs\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import bs4 as bs\n",
    "import pickle\n",
    "import requests\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session, role, bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()             # IAM role to use by SageMaker\n",
    "\n",
    "s3_bucket = sagemaker_session.default_bucket()\n",
    "s3_prefix = 'MLEND-Capstone-Project'    \n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)\n",
    "\n",
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sp500_tickers():\n",
    "    resp = requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "\n",
    "    soup = bs.BeautifulSoup(resp.text, \"lxml\")\n",
    "    table = soup.find('table', {'class':'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        ticker = ticker[:-1]\n",
    "        tickers.append(ticker)\n",
    "\n",
    "    with open('sp500tickers.pickle','wb') as f:\n",
    "        pickle.dump(tickers, f)\n",
    "    return tickers\n",
    "\n",
    "tickers = save_sp500_tickers()\n",
    "tickers.sort()\n",
    "tickers.remove('BF.B')\n",
    "tickers.remove('BRK.B')\n",
    "tickers.remove('CARR')\n",
    "tickers.remove('DPZ')\n",
    "tickers.remove('DXCM')\n",
    "tickers.remove('OTIS')\n",
    "tickers.remove('WST')\n",
    "\n",
    "hm_days = 7\n",
    "\n",
    "def buy_sell_hold(*args):\n",
    "    cols = [c for c in args]\n",
    "    requirement = 0.0235\n",
    "    for col in cols:\n",
    "        if col > requirement:\n",
    "            return 1\n",
    "        if col < -requirement:\n",
    "            return -1\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update\n"
     ]
    }
   ],
   "source": [
    "print('update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-259-526171401698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stocks_dfs/{}.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhm_days\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{}d'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast, **kwargs)\u001b[0m\n\u001b[1;32m   4032\u001b[0m                      \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4033\u001b[0m                                   \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4034\u001b[0;31m                                   downcast=downcast, **kwargs)\n\u001b[0m\u001b[1;32m   4035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4036\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   6128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_update_inplace\u001b[0;34m(self, result, verify_is_copy)\u001b[0m\n\u001b[1;32m   3854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3855\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3856\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverify_is_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_is_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[0;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[1;32m   3142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverify_is_copy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3144\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'referant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[0;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[1;32m   3243\u001b[0m             \u001b[0;31m# the copy weakref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3244\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3245\u001b[0;31m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3246\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_referents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3247\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import pytz\n",
    "\n",
    "data = OrderedDict()\n",
    "stock_data_preprocessed = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    df = pd.read_csv(\"stocks_dfs/{}.csv\".format(ticker), index_col=0, parse_dates=['Date'])\n",
    "    df = df[['Adj Close','Volume']]\n",
    "    df.fillna(0, inplace=True)\n",
    "    for i in range(1, hm_days+1):\n",
    "        df['{}d'.format(i)] = (df['Adj Close'].shift(-i) - df['Adj Close']) / df['Adj Close']\n",
    "        \n",
    "    '''df['50MA'] = df['Adj Close'].rolling(50).mean()\n",
    "    df['25MA'] = df['Adj Close'].rolling(25).mean()\n",
    "    df['10MA'] = df['Adj Close'].rolling(10).mean()\n",
    "    df['5MA'] = df['Adj Close'].rolling(5).mean()\n",
    "\n",
    "    df['50STD'] = df['Adj Close'].rolling(50).std()\n",
    "    df['25STD'] = df['Adj Close'].rolling(25).std()\n",
    "    df['10STD'] = df['Adj Close'].rolling(10).std()\n",
    "\n",
    "    df['50UBB'] = df['50MA'] + (df['50STD'] * 2)\n",
    "    df['25UBB'] = df['25MA'] + (df['25STD'] * 2)\n",
    "\n",
    "    df['50LBB'] = df['50MA'] - (df['50STD'] * 2)\n",
    "    df['25LBB'] = df['25MA'] - (df['25STD'] * 2)'''\n",
    "    \n",
    "    data[ticker] = df\n",
    "    \n",
    "\n",
    "stock_data_preprocessed = pd.concat(data.values(),keys=tickers,names=['Ticker','Date'])\n",
    "\n",
    "stock_data_preprocessed = stock_data_preprocessed.swaplevel()\n",
    "stock_data_preprocessed = stock_data_preprocessed.sort_index()\n",
    "#stock_data_preprocessed.to_csv('stock_data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b73b1987ad4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m stock_data_preprocessed['target'] = list(map( buy_sell_hold,\n\u001b[0;32m----> 2\u001b[0;31m                                                \u001b[0mstock_data_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1d'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                \u001b[0mstock_data_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2d'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                \u001b[0mstock_data_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3d'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                \u001b[0mstock_data_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'4d'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1d'"
     ]
    }
   ],
   "source": [
    "stock_data_preprocessed['target'] = list(map( buy_sell_hold,\n",
    "                                               stock_data_preprocessed['1d'.format(ticker)],\n",
    "                                               stock_data_preprocessed['2d'.format(ticker)],\n",
    "                                               stock_data_preprocessed['3d'.format(ticker)],\n",
    "                                               stock_data_preprocessed['4d'.format(ticker)],\n",
    "                                               stock_data_preprocessed['5d'.format(ticker)],\n",
    "                                               stock_data_preprocessed['6d'.format(ticker)],\n",
    "                                               stock_data_preprocessed['7d'.format(ticker)] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>1d</th>\n",
       "      <th>2d</th>\n",
       "      <th>3d</th>\n",
       "      <th>4d</th>\n",
       "      <th>5d</th>\n",
       "      <th>6d</th>\n",
       "      <th>7d</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2010-01-04</th>\n",
       "      <th>A</th>\n",
       "      <td>20.436504</td>\n",
       "      <td>3815500.0</td>\n",
       "      <td>-0.010862</td>\n",
       "      <td>-0.014377</td>\n",
       "      <td>-0.015655</td>\n",
       "      <td>-0.015975</td>\n",
       "      <td>-0.015336</td>\n",
       "      <td>-0.027157</td>\n",
       "      <td>-0.019489</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <td>4.496876</td>\n",
       "      <td>9837300.0</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.067086</td>\n",
       "      <td>0.098533</td>\n",
       "      <td>0.077568</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.064990</td>\n",
       "      <td>0.148847</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>39.293575</td>\n",
       "      <td>1701700.0</td>\n",
       "      <td>-0.005943</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>-0.003467</td>\n",
       "      <td>-0.020802</td>\n",
       "      <td>-0.007182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>26.538483</td>\n",
       "      <td>123432400.0</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>-0.014205</td>\n",
       "      <td>-0.016027</td>\n",
       "      <td>-0.009485</td>\n",
       "      <td>-0.018223</td>\n",
       "      <td>-0.029391</td>\n",
       "      <td>-0.015700</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABC</th>\n",
       "      <td>22.813559</td>\n",
       "      <td>2455900.0</td>\n",
       "      <td>-0.007134</td>\n",
       "      <td>-0.016522</td>\n",
       "      <td>-0.032294</td>\n",
       "      <td>-0.021780</td>\n",
       "      <td>-0.010890</td>\n",
       "      <td>-0.004131</td>\n",
       "      <td>0.015396</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Close       Volume        1d        2d        3d  \\\n",
       "Date       Ticker                                                         \n",
       "2010-01-04 A       20.436504    3815500.0 -0.010862 -0.014377 -0.015655   \n",
       "           AAL      4.496876    9837300.0  0.113208  0.067086  0.098533   \n",
       "           AAP     39.293575    1701700.0 -0.005943  0.002724  0.002476   \n",
       "           AAPL    26.538483  123432400.0  0.001729 -0.014205 -0.016027   \n",
       "           ABC     22.813559    2455900.0 -0.007134 -0.016522 -0.032294   \n",
       "\n",
       "                         4d        5d        6d        7d  target  \n",
       "Date       Ticker                                                  \n",
       "2010-01-04 A      -0.015975 -0.015336 -0.027157 -0.019489      -1  \n",
       "           AAL     0.077568  0.056604  0.064990  0.148847       1  \n",
       "           AAP     0.006439 -0.003467 -0.020802 -0.007182       0  \n",
       "           AAPL   -0.009485 -0.018223 -0.029391 -0.015700      -1  \n",
       "           ABC    -0.021780 -0.010890 -0.004131  0.015396      -1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['1d' '2d' '3d' '4d' '5d' '6d' '7d'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d70c0ee818b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstock_data_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2d'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'3d'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'4d'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'5d'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'6d'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'7d'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstock_data_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstock_data_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3940\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3779\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3780\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4964\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4965\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4967\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['1d' '2d' '3d' '4d' '5d' '6d' '7d'] not found in axis\""
     ]
    }
   ],
   "source": [
    "stock_data_preprocessed.drop(columns=['1d', '2d','3d','4d','5d','6d','7d'], inplace=True)\n",
    "stock_data_preprocessed.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "stock_data_preprocessed.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u\"None of [Index([u'Adj Close', u'Volume'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ed61af586083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstock_data_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_data_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mstock_data_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stock_data_preprocessed.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 raise KeyError(\n\u001b[1;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1246\u001b[0;31m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u\"None of [Index([u'Adj Close', u'Volume'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "stock_data_preprocessed[['Adj Close', 'Volume']] = scaler.fit_transform(stock_data_preprocessed[['Adj Close', 'Volume']])\n",
    "stock_data_preprocessed.to_csv('stock_data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-1: ', 1109910)\n",
      "(' 0: ', 1087758)\n",
      "(' 1: ', 1400007)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">2010-01-04</th>\n",
       "      <th>A</th>\n",
       "      <td>0.005248</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.011443</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>0.010092</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.006816</td>\n",
       "      <td>0.143586</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABC</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABMD</th>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABT</th>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.012597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACN</th>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADBE</th>\n",
       "      <td>0.009526</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADI</th>\n",
       "      <td>0.006230</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Adj Close    Volume  target\n",
       "Date       Ticker                             \n",
       "2010-01-04 A        0.005248  0.004438      -1\n",
       "           AAL      0.001154  0.011443       1\n",
       "           AAP      0.010092  0.001980       0\n",
       "           AAPL     0.006816  0.143586      -1\n",
       "           ABC      0.005859  0.002857      -1\n",
       "           ABMD     0.002244  0.000173      -1\n",
       "           ABT      0.004662  0.012597       1\n",
       "           ACN      0.008660  0.004246       0\n",
       "           ADBE     0.009526  0.005479      -1\n",
       "           ADI      0.006230  0.002446      -1"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data_preprocessed = pd.read_csv('stock_data_preprocessed.csv',parse_dates=True, index_col=[0,1])\n",
    "print(\"-1: \", stock_data_preprocessed[stock_data_preprocessed['target']==-1].size)\n",
    "print(\" 0: \", stock_data_preprocessed[stock_data_preprocessed['target']==0].size)\n",
    "print(\" 1: \", stock_data_preprocessed[stock_data_preprocessed['target']==1].size)\n",
    "stock_data_preprocessed.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use 2 hour frequency for the time series\n",
    "freq = 'D'\n",
    "\n",
    "# we predict for 7 days\n",
    "prediction_length = 1\n",
    "\n",
    "# we also use 7 days as context length, this is the number of state updates accomplished before making predictions\n",
    "context_length = 50\n",
    "\n",
    "end_training = pd.Timestamp(\"2018-12-31 00:00:00\", freq=freq)\n",
    "\n",
    "timeseries = []\n",
    "for ID,ticker in list(enumerate(tickers)):\n",
    "    ticker = stock_data_preprocessed.loc[(slice(None), ticker), :]\n",
    "    if ticker.index[0][0]<end_training:\n",
    "        timeseries.append(ticker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491\n"
     ]
    }
   ],
   "source": [
    "training_data = [\n",
    "    {\n",
    "            \"start\": str(ts.index[0][0]),\n",
    "            \"target\": ts['target'][ts.index[0][0]:end_training].tolist(), # We use -1, because pandas indexing includes the upper bound \n",
    "            \"dynamic_feat\": ts[['Adj Close','Volume']][ts.index[0][0]:end_training].values.T.tolist()\n",
    "    }\n",
    "    for ts in timeseries\n",
    "]\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/ipykernel/__main__.py:10: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4910\n"
     ]
    }
   ],
   "source": [
    "num_test_windows = 10\n",
    "\n",
    "test_data_2 = [\n",
    "    {\n",
    "        \"start\": str(ts.index[0][0]),\n",
    "        \"target\": ts['target'][ts.index[0][0]:end_training + (2*k * prediction_length)].tolist(),\n",
    "        \"dynamic_feat\": ts[['Adj Close','Volume']][ts.index[0][0]:end_training + (2*k * prediction_length)].values.T.tolist()\n",
    "    }\n",
    "    for k in range(1, num_test_windows + 1) \n",
    "    for ts in timeseries\n",
    "]\n",
    "print(len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_dataset(filename, data): \n",
    "    with open(filename, 'wb') as f:\n",
    "        # for each of our times series, there is one JSON line\n",
    "        for d in data:\n",
    "            json_line = json.dumps(d) + '\\n'\n",
    "            json_line = json_line.encode('utf-8')\n",
    "            f.write(json_line)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 21s, sys: 1.35 s, total: 2min 23s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_json_dataset(\"train.json\", training_data)\n",
    "write_json_dataset(\"test.json\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith('s3://')\n",
    "    split = s3_path.split('/')\n",
    "    bucket = split[2]\n",
    "    path = '/'.join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "    \n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print('File s3://{}/{} already exists.\\nSet override to upload anyway.\\n'.format(s3_bucket, s3_path))\n",
    "            return\n",
    "        else:\n",
    "            print('Overwriting existing file')\n",
    "    with open(local_file, 'rb') as data:\n",
    "        print('Uploading file to {}'.format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file to s3://sagemaker-us-east-2-017500148529/MLEND-Capstone-Project/data/train/train.json\n",
      "Uploading file to s3://sagemaker-us-east-2-017500148529/MLEND-Capstone-Project/data/test/test.json\n",
      "CPU times: user 4 s, sys: 1.36 s, total: 5.35 s\n",
      "Wall time: 23.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "copy_to_s3(\"train.json\", s3_data_path + \"/train/train.json\")\n",
    "copy_to_s3(\"test.json\", s3_data_path + \"/test/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2010-01-04 00:00:00\", \"target\": [-1, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...\n"
     ]
    }
   ],
   "source": [
    "s3filesystem = s3fs.S3FileSystem()\n",
    "with s3filesystem.open(s3_data_path + \"/train/train.json\", 'rb') as fp:\n",
    "    print(fp.readline().decode(\"utf-8\")[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='MLEND-Capstone-Project',\n",
    "    output_path=s3_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"10\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"num_dynamic_feat\": 'auto',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-01 00:27:34 Starting - Starting the training job...\n",
      "2020-06-01 00:27:37 Starting - Launching requested ML instances......\n",
      "2020-06-01 00:28:40 Starting - Preparing the instances for training......\n",
      "2020-06-01 00:30:00 Downloading - Downloading input data\n",
      "2020-06-01 00:30:00 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'num_dynamic_feat': u'auto', u'learning_rate': u'5E-4', u'prediction_length': u'1', u'epochs': u'10', u'time_freq': u'D', u'context_length': u'50', u'mini_batch_size': u'64', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'10', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'1', u'time_freq': u'D', u'context_length': u'50', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=2 from dataset.\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] Training set statistics:\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] Real time series\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] number of time series: 491\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] number of observations: 1074589\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] mean target length: 2188\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] min/mean/max target: -1.0/0.0764683055568/1.0\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] mean abs(target): 0.698935127756\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] contains missing values: no\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:16 INFO 140489765541696] Small number of time series. Doing 2 passes over dataset with prob 0.651731160896 per epoch.\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:20 INFO 140489765541696] Test set statistics:\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:20 INFO 140489765541696] Real time series\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:20 INFO 140489765541696] number of time series: 4910\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:20 INFO 140489765541696] number of observations: 10781660\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:20 INFO 140489765541696] mean target length: 2195\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:20 INFO 140489765541696] min/mean/max target: -1.0/0.078016464997/1.0\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:20 INFO 140489765541696] mean abs(target): 0.699434317165\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:20 INFO 140489765541696] contains missing values: no\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:20 INFO 140489765541696] nvidia-smi took: 0.0251760482788 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:20 INFO 140489765541696] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:20 INFO 140489765541696] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 235.60380935668945, \"sum\": 235.60380935668945, \"min\": 235.60380935668945}}, \"EndTime\": 1590971420.712562, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971420.476019}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:20 INFO 140489765541696] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 434.7951412200928, \"sum\": 434.7951412200928, \"min\": 434.7951412200928}}, \"EndTime\": 1590971420.910954, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971420.71264}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:21 INFO 140489765541696] Epoch[0] Batch[0] avg_epoch_loss=1.383354\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:21 INFO 140489765541696] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=1.38335394859\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:21 INFO 140489765541696] Epoch[0] Batch[5] avg_epoch_loss=1.366484\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:21 INFO 140489765541696] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=1.36648400625\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:21 INFO 140489765541696] Epoch[0] Batch [5]#011Speed: 1040.86 samples/sec#011loss=1.366484\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:22 INFO 140489765541696] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"update.time\": {\"count\": 1, \"max\": 1565.2968883514404, \"sum\": 1565.2968883514404, \"min\": 1565.2968883514404}}, \"EndTime\": 1590971422.476388, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971420.911016}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:22 INFO 140489765541696] #throughput_metric: host=algo-1, train throughput=394.779006263 records/second\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:22 INFO 140489765541696] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:22 INFO 140489765541696] #quality_metric: host=algo-1, epoch=0, train loss <loss>=1.32967811823\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:22 INFO 140489765541696] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:22 INFO 140489765541696] Saved checkpoint to \"/opt/ml/model/state_f27a5ee4-c22d-4d20-a4ec-6e9d281403d4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.49002456665039, \"sum\": 22.49002456665039, \"min\": 22.49002456665039}}, \"EndTime\": 1590971422.49954, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971422.476487}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:23 INFO 140489765541696] Epoch[1] Batch[0] avg_epoch_loss=1.278607\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:23 INFO 140489765541696] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=1.27860713005\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:23 INFO 140489765541696] Epoch[1] Batch[5] avg_epoch_loss=1.277999\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:23 INFO 140489765541696] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=1.27799910307\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:23 INFO 140489765541696] Epoch[1] Batch [5]#011Speed: 969.81 samples/sec#011loss=1.277999\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:24 INFO 140489765541696] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1641.2019729614258, \"sum\": 1641.2019729614258, \"min\": 1641.2019729614258}}, \"EndTime\": 1590971424.140868, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971422.499606}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:24 INFO 140489765541696] #throughput_metric: host=algo-1, train throughput=383.227189401 records/second\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:24 INFO 140489765541696] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:24 INFO 140489765541696] #quality_metric: host=algo-1, epoch=1, train loss <loss>=1.28214641809\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:24 INFO 140489765541696] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:24 INFO 140489765541696] Saved checkpoint to \"/opt/ml/model/state_e062d3e2-b080-4ed6-884b-5946056d80a7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 33.065080642700195, \"sum\": 33.065080642700195, \"min\": 33.065080642700195}}, \"EndTime\": 1590971424.174632, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971424.140951}\n",
      "\u001b[0m\n",
      "\n",
      "2020-06-01 00:30:13 Training - Training image download completed. Training in progress.\u001b[34m[06/01/2020 00:30:24 INFO 140489765541696] Epoch[2] Batch[0] avg_epoch_loss=1.196939\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:24 INFO 140489765541696] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=1.19693863392\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:25 INFO 140489765541696] Epoch[2] Batch[5] avg_epoch_loss=1.236816\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:25 INFO 140489765541696] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=1.23681626717\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:25 INFO 140489765541696] Epoch[2] Batch [5]#011Speed: 1076.66 samples/sec#011loss=1.236816\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:25 INFO 140489765541696] Epoch[2] Batch[10] avg_epoch_loss=1.253147\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:25 INFO 140489765541696] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=1.27274377346\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:25 INFO 140489765541696] Epoch[2] Batch [10]#011Speed: 511.29 samples/sec#011loss=1.272744\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:25 INFO 140489765541696] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1592.419147491455, \"sum\": 1592.419147491455, \"min\": 1592.419147491455}}, \"EndTime\": 1590971425.767243, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971424.174705}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:25 INFO 140489765541696] #throughput_metric: host=algo-1, train throughput=405.014641648 records/second\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:25 INFO 140489765541696] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:25 INFO 140489765541696] #quality_metric: host=algo-1, epoch=2, train loss <loss>=1.25314695185\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:25 INFO 140489765541696] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:25 INFO 140489765541696] Saved checkpoint to \"/opt/ml/model/state_97a53781-6e98-4fd2-aa8b-3d7949e16008-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 31.435012817382812, \"sum\": 31.435012817382812, \"min\": 31.435012817382812}}, \"EndTime\": 1590971425.799225, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971425.76732}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:26 INFO 140489765541696] Epoch[3] Batch[0] avg_epoch_loss=1.212687\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:26 INFO 140489765541696] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=1.21268689632\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:26 INFO 140489765541696] Epoch[3] Batch[5] avg_epoch_loss=1.187655\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:26 INFO 140489765541696] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=1.1876552701\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:26 INFO 140489765541696] Epoch[3] Batch [5]#011Speed: 1059.96 samples/sec#011loss=1.187655\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:27 INFO 140489765541696] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1439.2459392547607, \"sum\": 1439.2459392547607, \"min\": 1439.2459392547607}}, \"EndTime\": 1590971427.238585, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971425.799285}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:27 INFO 140489765541696] #throughput_metric: host=algo-1, train throughput=432.135603597 records/second\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:27 INFO 140489765541696] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:27 INFO 140489765541696] #quality_metric: host=algo-1, epoch=3, train loss <loss>=1.1831389308\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:27 INFO 140489765541696] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:27 INFO 140489765541696] Saved checkpoint to \"/opt/ml/model/state_972a4d6c-3839-45b7-aaa0-60c839733a12-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 26.62205696105957, \"sum\": 26.62205696105957, \"min\": 26.62205696105957}}, \"EndTime\": 1590971427.265792, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971427.238667}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:27 INFO 140489765541696] Epoch[4] Batch[0] avg_epoch_loss=1.288647\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:27 INFO 140489765541696] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=1.28864729404\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:28 INFO 140489765541696] Epoch[4] Batch[5] avg_epoch_loss=1.236900\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:28 INFO 140489765541696] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=1.23690025012\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:28 INFO 140489765541696] Epoch[4] Batch [5]#011Speed: 1059.27 samples/sec#011loss=1.236900\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:28 INFO 140489765541696] Epoch[4] Batch[10] avg_epoch_loss=1.229623\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:28 INFO 140489765541696] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=1.22089054585\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:28 INFO 140489765541696] Epoch[4] Batch [10]#011Speed: 523.62 samples/sec#011loss=1.220891\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:28 INFO 140489765541696] processed a total of 685 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1523.6918926239014, \"sum\": 1523.6918926239014, \"min\": 1523.6918926239014}}, \"EndTime\": 1590971428.789602, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971427.265855}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:28 INFO 140489765541696] #throughput_metric: host=algo-1, train throughput=449.532613157 records/second\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:28 INFO 140489765541696] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:28 INFO 140489765541696] #quality_metric: host=algo-1, epoch=4, train loss <loss>=1.22962311181\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:28 INFO 140489765541696] loss did not improve\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:29 INFO 140489765541696] Epoch[5] Batch[0] avg_epoch_loss=1.218588\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:29 INFO 140489765541696] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=1.21858847141\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:29 INFO 140489765541696] Epoch[5] Batch[5] avg_epoch_loss=1.167140\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:29 INFO 140489765541696] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=1.16714048386\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:29 INFO 140489765541696] Epoch[5] Batch [5]#011Speed: 1086.89 samples/sec#011loss=1.167140\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:30 INFO 140489765541696] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1428.2729625701904, \"sum\": 1428.2729625701904, \"min\": 1428.2729625701904}}, \"EndTime\": 1590971430.218374, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971428.78968}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:30 INFO 140489765541696] #throughput_metric: host=algo-1, train throughput=443.163078012 records/second\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:30 INFO 140489765541696] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:30 INFO 140489765541696] #quality_metric: host=algo-1, epoch=5, train loss <loss>=1.18002935648\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:30 INFO 140489765541696] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:30 INFO 140489765541696] Saved checkpoint to \"/opt/ml/model/state_13e95174-88cc-4e94-9ffd-abf43ee33770-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.687103271484375, \"sum\": 20.687103271484375, \"min\": 20.687103271484375}}, \"EndTime\": 1590971430.239659, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971430.218436}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:30 INFO 140489765541696] Epoch[6] Batch[0] avg_epoch_loss=1.158017\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:30 INFO 140489765541696] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=1.15801656246\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:31 INFO 140489765541696] Epoch[6] Batch[5] avg_epoch_loss=1.147999\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:31 INFO 140489765541696] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=1.14799910784\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:31 INFO 140489765541696] Epoch[6] Batch [5]#011Speed: 1027.57 samples/sec#011loss=1.147999\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:31 INFO 140489765541696] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1399.6858596801758, \"sum\": 1399.6858596801758, \"min\": 1399.6858596801758}}, \"EndTime\": 1590971431.639458, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971430.239717}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:31 INFO 140489765541696] #throughput_metric: host=algo-1, train throughput=447.204210369 records/second\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:31 INFO 140489765541696] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:31 INFO 140489765541696] #quality_metric: host=algo-1, epoch=6, train loss <loss>=1.13407012224\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:31 INFO 140489765541696] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:31 INFO 140489765541696] Saved checkpoint to \"/opt/ml/model/state_46336356-0e51-49c5-8947-fd7bbab35f93-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.54882049560547, \"sum\": 20.54882049560547, \"min\": 20.54882049560547}}, \"EndTime\": 1590971431.660634, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971431.639542}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:32 INFO 140489765541696] Epoch[7] Batch[0] avg_epoch_loss=1.145430\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:32 INFO 140489765541696] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=1.14542984962\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:32 INFO 140489765541696] Epoch[7] Batch[5] avg_epoch_loss=1.156469\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:32 INFO 140489765541696] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=1.15646912654\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:32 INFO 140489765541696] Epoch[7] Batch [5]#011Speed: 1081.71 samples/sec#011loss=1.156469\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:33 INFO 140489765541696] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1433.2330226898193, \"sum\": 1433.2330226898193, \"min\": 1433.2330226898193}}, \"EndTime\": 1590971433.09398, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971431.660691}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:33 INFO 140489765541696] #throughput_metric: host=algo-1, train throughput=443.016898756 records/second\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:33 INFO 140489765541696] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:33 INFO 140489765541696] #quality_metric: host=algo-1, epoch=7, train loss <loss>=1.13372193575\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:33 INFO 140489765541696] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:33 INFO 140489765541696] Saved checkpoint to \"/opt/ml/model/state_f38a5ec5-5c13-497b-ba5c-ebec4f4f8758-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 21.358966827392578, \"sum\": 21.358966827392578, \"min\": 21.358966827392578}}, \"EndTime\": 1590971433.115927, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971433.094064}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:33 INFO 140489765541696] Epoch[8] Batch[0] avg_epoch_loss=1.134721\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:33 INFO 140489765541696] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=1.1347206831\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:34 INFO 140489765541696] Epoch[8] Batch[5] avg_epoch_loss=1.103386\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:34 INFO 140489765541696] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=1.10338600477\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:34 INFO 140489765541696] Epoch[8] Batch [5]#011Speed: 1078.23 samples/sec#011loss=1.103386\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:34 INFO 140489765541696] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1436.5911483764648, \"sum\": 1436.5911483764648, \"min\": 1436.5911483764648}}, \"EndTime\": 1590971434.552631, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971433.115989}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:34 INFO 140489765541696] #throughput_metric: host=algo-1, train throughput=435.030452829 records/second\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:34 INFO 140489765541696] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:34 INFO 140489765541696] #quality_metric: host=algo-1, epoch=8, train loss <loss>=1.07571862936\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:34 INFO 140489765541696] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:34 INFO 140489765541696] Saved checkpoint to \"/opt/ml/model/state_56f80ecb-3e20-4571-83a2-94bdbef4ae6d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.507097244262695, \"sum\": 20.507097244262695, \"min\": 20.507097244262695}}, \"EndTime\": 1590971434.57377, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971434.552692}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 INFO 140489765541696] Epoch[9] Batch[0] avg_epoch_loss=1.177100\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 INFO 140489765541696] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=1.17709994316\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 INFO 140489765541696] Epoch[9] Batch[5] avg_epoch_loss=1.077137\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 INFO 140489765541696] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=1.07713704308\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 INFO 140489765541696] Epoch[9] Batch [5]#011Speed: 566.12 samples/sec#011loss=1.077137\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 INFO 140489765541696] processed a total of 576 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1316.6558742523193, \"sum\": 1316.6558742523193, \"min\": 1316.6558742523193}}, \"EndTime\": 1590971435.890558, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971434.573836}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 INFO 140489765541696] #throughput_metric: host=algo-1, train throughput=437.436057961 records/second\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 INFO 140489765541696] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 INFO 140489765541696] #quality_metric: host=algo-1, epoch=9, train loss <loss>=1.09236691395\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 INFO 140489765541696] loss did not improve\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 INFO 140489765541696] Final loss: 1.07571862936 (occurred at epoch 8)\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 INFO 140489765541696] #quality_metric: host=algo-1, train final_loss <loss>=1.07571862936\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 INFO 140489765541696] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 WARNING 140489765541696] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:35 INFO 140489765541696] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 244.62294578552246, \"sum\": 244.62294578552246, \"min\": 244.62294578552246}}, \"EndTime\": 1590971436.13618, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971435.890635}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:36 INFO 140489765541696] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 304.04019355773926, \"sum\": 304.04019355773926, \"min\": 304.04019355773926}}, \"EndTime\": 1590971436.195562, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971436.136246}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:36 INFO 140489765541696] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:36 INFO 140489765541696] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 8.455991744995117, \"sum\": 8.455991744995117, \"min\": 8.455991744995117}}, \"EndTime\": 1590971436.204136, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971436.195638}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:36 INFO 140489765541696] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:36 INFO 140489765541696] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.03790855407714844, \"sum\": 0.03790855407714844, \"min\": 0.03790855407714844}}, \"EndTime\": 1590971436.204852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971436.20418}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:39 INFO 140489765541696] Number of test batches scored: 10\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:42 INFO 140489765541696] Number of test batches scored: 20\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:45 INFO 140489765541696] Number of test batches scored: 30\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:48 INFO 140489765541696] Number of test batches scored: 40\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:51 INFO 140489765541696] Number of test batches scored: 50\u001b[0m\n",
      "\n",
      "2020-06-01 00:31:06 Uploading - Uploading generated training model\n",
      "2020-06-01 00:31:06 Completed - Training job completed\n",
      "\u001b[34m[06/01/2020 00:30:53 INFO 140489765541696] Number of test batches scored: 60\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:56 INFO 140489765541696] Number of test batches scored: 70\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 22685.595989227295, \"sum\": 22685.595989227295, \"min\": 22685.595989227295}}, \"EndTime\": 1590971458.890409, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971436.204912}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:58 INFO 140489765541696] #test_score (algo-1, RMSE): 0.744281273417\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:58 INFO 140489765541696] #test_score (algo-1, mean_absolute_QuantileLoss): 2263.5308479734795\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:58 INFO 140489765541696] #test_score (algo-1, mean_wQuantileLoss): 0.5718875310696008\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:58 INFO 140489765541696] #test_score (algo-1, wQuantileLoss[0.1]): 0.3738502437445538\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:58 INFO 140489765541696] #test_score (algo-1, wQuantileLoss[0.2]): 0.5793189969416398\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:58 INFO 140489765541696] #test_score (algo-1, wQuantileLoss[0.3]): 0.7023141129540035\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:58 INFO 140489765541696] #test_score (algo-1, wQuantileLoss[0.4]): 0.757961069836181\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:58 INFO 140489765541696] #test_score (algo-1, wQuantileLoss[0.5]): 0.7392427612968098\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:58 INFO 140489765541696] #test_score (algo-1, wQuantileLoss[0.6]): 0.663396136370827\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:58 INFO 140489765541696] #test_score (algo-1, wQuantileLoss[0.7]): 0.5706282853888194\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:58 INFO 140489765541696] #test_score (algo-1, wQuantileLoss[0.8]): 0.4579769653539696\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:58 INFO 140489765541696] #test_score (algo-1, wQuantileLoss[0.9]): 0.3022992077396034\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:58 INFO 140489765541696] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.57188753107\u001b[0m\n",
      "\u001b[34m[06/01/2020 00:30:58 INFO 140489765541696] #quality_metric: host=algo-1, test RMSE <loss>=0.744281273417\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 42569.748878479004, \"sum\": 42569.748878479004, \"min\": 42569.748878479004}, \"setuptime\": {\"count\": 1, \"max\": 9.142875671386719, \"sum\": 9.142875671386719, \"min\": 9.142875671386719}}, \"EndTime\": 1590971458.907418, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1590971458.890474}\n",
      "\u001b[0m\n",
      "Training seconds: 89\n",
      "Billable seconds: 89\n",
      "CPU times: user 1.25 s, sys: 90.4 ms, total: 1.34 s\n",
      "Wall time: 3min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\n",
    "    \"train\": s3_data_path + \"/train/train.json\",\n",
    "    \"test\": s3_data_path + \"/test/test.json\"\n",
    "}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor = estimator.deploy(\n",
    "#    initial_instance_count=1,\n",
    "#    instance_type='ml.m4.xlarge',\n",
    "#    content_type=\"application/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_request(instance, num_samples, quantiles):\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\"],\n",
    "            \"quantiles\": quantiles\n",
    "        }\n",
    "        \n",
    "        http_request_data = {\n",
    "            \"instances\": [instance],\n",
    "            \"configuration\": configuration\n",
    "        }\n",
    "        \n",
    "        return json.dumps(http_request_data).encode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.predictor.RealTimePredictor(endpoint='MLEND-Capstone-Project-2020-05-31-23-12-35-007')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_prediction(ticker,date):\n",
    "    try:\n",
    "        date_pred = pd.Timestamp(date, freq='D')\n",
    "        date_start = date_pred-50\n",
    "        pred_df = stock_data_preprocessed.loc[(slice(str(date_start),str(date_pred)), ticker), :]\n",
    "        result_df = pred_df.loc[(slice(str(date_pred),str(date_pred)), ticker), :]\n",
    "\n",
    "        pred = {\n",
    "                \"start\": str(date_pred),\n",
    "                \"target\": pred_df['target'][date_start:date_pred-1].tolist(),\n",
    "                \"dynamic_feat\": pred_df[['Adj Close','Volume']][date_start:date_pred].values.T.tolist()\n",
    "        }\n",
    "\n",
    "        req = encode_request(instance=pred, num_samples=50, quantiles=['0.1', '0.5', '0.9'])\n",
    "        res = predictor.predict(req)\n",
    "\n",
    "        prediction_data = json.loads(res.decode('utf-8'))\n",
    "        pred = round(prediction_data['predictions'][0]['quantiles']['0.5'][0])\n",
    "        result_df['prediction'] = pred\n",
    "        return result_df\n",
    "    except:\n",
    "        print('{} did not trade today.'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stock_prediction('AAPL', '2019-01-23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL did not trade today.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/ipykernel/__main__.py:7: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/ipykernel/__main__.py:4: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/ipykernel/__main__.py:10: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-415-27a5e769e137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#for i in range(200):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_stock_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AAPL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_stock_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AAPL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "date = pd.Timestamp(\"2019-01-19\", freq='D')\n",
    "i = 0\n",
    "target = []\n",
    "prediction = []\n",
    "\n",
    "#for i in range(200):\n",
    "d = date+i\n",
    "print(get_stock_prediction('AAPL', str(d))['target'].values[0])\n",
    "print(int(get_stock_prediction('AAPL', str(d))['prediction'].values[0]))\n",
    "\n",
    "   # prediction.append(get_stock_prediction('AAPL', str(d))['prediction'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Date        Ticker\n",
       " 2019-01-16  AAPL      0\n",
       " Name: target, dtype: int64, Date        Ticker\n",
       " 2019-01-17  AAPL      0\n",
       " Name: target, dtype: int64, Date        Ticker\n",
       " 2019-01-18  AAPL     -1\n",
       " Name: target, dtype: int64]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
